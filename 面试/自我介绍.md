您好，我是于悦，来自东南大学软件工程专业，目前是本科三年级的学生。我对技术充满热情，特别是在全栈开发、AI技术和大语言模型的应用开发方面积累了丰富的实践经验。

在技术方面，我熟练掌握Java、C++、Python等编程语言，并且对后端开发和前端开发都有较深的理解。作为一个全栈开发者，我曾独立完成多个项目，包括基于**Neo4j图数据库**和**SpringBoot**框架的知识图谱学习系统，以及基于**DeepSeek**和**Ollama**的AI聊天机器人。在这些项目中，我不仅参与了系统架构的设计，还深度优化了技术实现，提升了系统的效率和可扩展性。

在AI相关的开发中，我深入学习并应用了**RAG（检索增强生成）技术**，使用**Ollama**和**Qdrant**等工具实现了基于语义检索的对话系统。在**AI QQ聊天机器人**项目中，我实现了具有长期记忆和多角色切换的个性化对话系统，支持对话的上下文理解和智能回复。

我也有丰富的团队合作经验，曾作为**东南大学 I++ 开源社团的核心成员**，组织并参与了多个技术分享会，推动了开源技术在社团中的传播。通过这些活动，我不仅提升了自己的技术水平，也学会了如何与团队高效协作。

在未来的职业生涯中，我希望能够将我的全栈开发能力与AI技术应用相结合，参与更多前沿项目的开发与优化。相信我的技术积累、团队协作经验和解决问题的能力，能够为贵公司的发展贡献力量。


以下是针对这些问题的详细回答，希望能帮助你在面试中充分展示自己的能力和理解：

---

### 技术类问题

#### 1. 你了解模型量化吗？为什么要做？

模型量化是指将训练好的浮动点模型（如32位浮点数）转化为低精度表示（如8位整数）的过程。量化的主要目的是在不显著降低模型精度的情况下，减少模型的计算资源和存储需求，从而提高推理速度和降低部署成本。量化通常能显著减小模型的体积，并加速推理过程，尤其在边缘设备或资源有限的环境中具有重要意义。

#### 2. 你知道LoRA和P-Tuning有什么区别吗？

**LoRA**（Low-Rank Adaptation）和**P-Tuning**都是模型微调技术，但它们的核心思想和实现方式不同：

- **LoRA**：通过对预训练模型的参数进行低秩矩阵的近似，在微调过程中仅更新低秩矩阵的参数，而保持原始预训练模型的大部分参数不变。它的优势是可以大幅减少训练参数量，提高微调的效率，尤其在需要适应多任务时，LoRA可以节省显存和计算资源。
    
- **P-Tuning**：P-Tuning通过引入可调的提示（prompt）来引导模型进行任务微调，适用于预训练语言模型。它的核心思想是通过精心设计的提示模板使模型能够更好地理解特定任务，而无需大规模微调模型的参数。P-Tuning的优势在于不需要大量的数据和计算资源，也能获得相对较好的效果。
    

总结：LoRA侧重于通过低秩矩阵更新模型参数，而P-Tuning侧重于通过提示调整模型行为，二者在应用场景和技术实现上有所不同。

#### 3. 你是如何做Langchain搭建/应用开发的？

在Langchain的搭建和应用开发中，通常涉及以下几个步骤：

1. **选择语言模型**：首先选择合适的语言模型（如OpenAI的GPT、Hugging Face的Transformers等），并设置与之交互的API。
    
2. **定义链（Chain）**：Langchain允许我们定义一系列操作（如文本预处理、调用模型、后处理等），这些操作可以组成一个链来实现复杂的任务。例如，通过链式结构实现自然语言的多步骤推理和生成。
    
3. **集成外部工具**：Langchain支持与外部工具（如数据库、API、文件系统等）集成，以扩展模型的功能。例如，结合数据库进行信息检索、结合文件系统进行数据读取。
    
4. **开发与调优**：根据需求开发自定义链、转换器或记忆模块，并进行调优，确保多轮对话、上下文理解等功能的实现。
    

在应用开发中，常见的问题包括链的优化、API调用的效率问题，以及如何在多任务环境中保持良好的性能。

---

### 项目类问题

#### 1. 聊天机器人中RAG架构具体是怎么实现的？遇到什么问题？

**RAG（检索增强生成）**架构是通过将生成式模型与检索式模型结合来提高对话的质量和准确性。在我的聊天机器人项目中，RAG架构的实现包括以下步骤：

1. **文本向量化**：使用Ollama进行文本的向量化，将文本转化为高维向量表示。
    
2. **语义检索**：通过Qdrant作为向量数据库，进行高效的相似度检索，找到与用户查询相关的上下文信息。
    
3. **生成式回答**：将检索到的上下文信息与用户输入合并，传递给大语言模型（如GPT）进行回答生成。
    

遇到的主要问题包括：

- **语义匹配的精度问题**：有时检索到的内容与用户意图不完全匹配，导致生成的回答不准确。为此，我们优化了向量化模型和检索策略，采用了多轮对话上下文的方式，提升了回答的相关性。
    
- **性能瓶颈**：在实时系统中，向量检索和生成的速度是关键，我们通过压缩向量、优化索引等手段提高了响应速度。
    

#### 2. 知识图谱系统中，前后端怎么协作？Neo4j数据库是怎么建模的？

在**知识图谱系统**中，前后端的协作通过API进行数据交互，前端通过Vue.js请求后端的RESTful API，获取知识点数据，并展示给用户。后端使用SpringBoot框架提供API，并与Neo4j图数据库进行交互，执行图查询操作。

**Neo4j数据库建模**方面，我们将知识图谱中的实体（如学科、知识点、题目等）作为节点（node）来建模，实体之间的关系（如“属于”、“包含”等）则通过边（relationship）表示。每个节点和边都可以有属性，用于存储额外的元数据。通过这种建模方式，可以高效地表示和查询复杂的知识结构。

#### 3. 在项目中你是怎么保证代码质量和项目进度的？

我通常通过以下方法来保证代码质量和项目进度：

- **代码规范**：在团队内部制定统一的代码规范，使用工具（如Checkstyle、SonarQube）进行自动化代码检查，确保代码的一致性和可维护性。
    
- **代码评审**：实施代码评审流程，通过团队成员间的互审，及时发现并解决代码中的问题。
    
- **单元测试与集成测试**：通过编写单元测试和集成测试，确保代码的稳定性和功能的正确性。
    
- **项目管理工具**：使用GitLab、Trello等项目管理工具进行任务分解和进度追踪，确保项目按时推进。
    

---

### 综合类问题

#### 1. 如果让你部署一个100亿参数的大模型，你会怎么做？

部署一个100亿参数的大模型，需要考虑多个方面：

1. **硬件要求**：由于大模型需要巨大的计算资源，我会选择使用多GPU集群进行推理，或者考虑使用TPU等专用硬件加速器。
    
2. **分布式计算**：采用分布式训练和推理框架，如TensorFlow或PyTorch的分布式模块，将模型分布到多个设备上，减少内存和计算压力。
    
3. **模型压缩与量化**：考虑使用模型压缩、量化等技术，减少模型存储和计算开销。
    
4. **云服务与弹性扩展**：部署在云服务平台上，利用弹性计算资源，根据负载动态扩展机器集群。
    

#### 2. 你觉得Agent系统设计的难点在哪里？

Agent系统设计的难点主要在于以下几个方面：

- **多任务协调与决策**：Agent系统通常需要执行多个任务或处理多个需求，如何设计高效的任务调度和决策机制是关键。
    
- **状态管理**：Agent系统需要持续感知环境并作出相应决策，如何有效地管理Agent的状态（如感知、行动、学习）是挑战。
    
- **自适应与学习**：Agent系统需要能够根据环境的变化进行自我调整，如何设计合理的学习机制，以适应不同的场景，是系统设计中的难点。
    

#### 3. 你平时怎么学习新技术？遇到陌生领域怎么办？

我通常通过以下方式学习新技术：

- **阅读文档和官方资料**：我习惯阅读技术文档，特别是开源项目的文档，通过理解官方文档来入门新技术。
    
- **实践项目**：我通过参与实际项目，将新学到的技术应用到开发中，增强对技术的理解。
    
- **技术分享与社区互动**：我积极参加技术分享会和开源社区活动，向他人学习并分享自己的经验。
    

遇到陌生领域时，我会首先进行基础学习，结合在线课程、博客等资料深入理解，然后通过小规模的实验或项目逐步积累经验，遇到问题时查阅资料或向社区求助。

---

希望这些回答能帮助你准备面试。