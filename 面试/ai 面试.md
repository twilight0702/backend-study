# 岗位要求

## 1 优泰

岗位职责： 
1. 参与大模型技术研究与学习，（如Transformer架构、Prompt Engineering、RLHF等）
2.  协助大模型的部署优化，包括模型量化、分布式推理、服务化部署（Hugging Face/DeepSpeed等工具链实践） 
3. 支持大模型训练全流程，涵盖数据清洗、分布式训练加速、模型微调（LoRA/P-Tuning等参数高效方法） 
4. 探索大模型应用场景，参与构建行业垂直领域智能体（如Agent系统、知识库问答等） 5. 完成技术文档沉淀与知识分享，协助团队构建技术资产 

任职要求： 
1. 985、211在校（大三+）学生优先考虑，每周实习1-4天，持续2个月； 
2. 熟悉OpenWebUI、Langchain等项目，能够部署、修改； 
3. 熟练掌握至少一种编程语言，如Python（最常见，包括numpy、pandas、scikit-learn、PyTorch、TensorFlow等库的使用），或C++等； 
4. 掌握深度学习基础理论，理解Transformer/BERT/GPT等模型架构，有Hugging Face库使用经验加分； 
5. 熟悉RAG技术；有基于Rag构建垂直领域知识库经验者优先。 
6. 熟悉MCP协议、A2AI协议，有MCP服务器构建经验者优先。 
7. 熟悉vllm、llama.cpp等模型推理框架，有模型量化、分布式推理、服务化部署经验者优先。 
8. 具备良好的团队合作精神，能够有效沟通，积极解决技术难题。

## 2 福尔摩斯

工作内容主要负责机器人及无人驾驶系统的程序编写，python为新兴编程语言，允许新员工有1-2个月的适应学习期，欢迎学习能力强的朋友投简历

（感觉这个就随便了（？））

# 准备计划

## 知识点

### ✅ 1. 大模型基本理论

- Transformer 架构原理（Attention机制、Position Encoding等）
    
- BERT、GPT 系列区别（预训练目标、结构差异、用途等）
    
- LoRA、P-Tuning、Adapter等轻量微调方式的原理与适用场景
    
- RLHF（强化学习人类反馈）大致流程：SFT → Reward Model → PPO
    

### ✅ 2. 工具链与框架实践

- **Hugging Face Transformers**：模型加载、训练、推理、Tokenizer使用
    
- **Langchain**：了解其模块化结构（LLM、Memory、Chain、Agent等）
    
- **OpenWebUI**：熟悉部署方式、配置文件、功能模块
    
- **DeepSpeed / vLLM / llama.cpp**：看一下官方文档和基本启动流程
    
- **RAG（Retrieval-Augmented Generation）**：
    
    - 原理：Retriever + Generator 组合方式
        
    - VectorDB（如FAISS, Milvus等）的使用
        
    - Langchain中实现RAG的方法
        

### ✅ 3. 编程与实践能力

- Python项目经验（掌握面向对象、异常处理、调试等）
    
- 熟悉数据清洗（pandas）、深度学习框架（PyTorch 优先）

### 语言

python再熟悉熟悉，还有java同步进行，还是有太多不会的了

## 项目准备

深挖一下项目，准备一下会被问到的问题

## 自我介绍

